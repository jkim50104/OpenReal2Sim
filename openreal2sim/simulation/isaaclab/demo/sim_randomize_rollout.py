"""
Heuristic manipulation policy in Isaac Lab simulation.
Using grasping and motion planning to perform object manipulation tasks.
"""
from __future__ import annotations

# ─────────── AppLauncher ───────────
import argparse, os, json, random, transforms3d
from pathlib import Path
import numpy as np
import torch
import yaml
import sys
from isaaclab.app import AppLauncher
from typing import Optional, List
import copy
file_path = Path(__file__).resolve()
import imageio 

sys.path.append(str(file_path.parent))
sys.path.append(str(file_path.parent.parent))
from envs.task_cfg import TaskCfg, TaskType, SuccessMetric, SuccessMetricType, TrajectoryCfg
from envs.task_construct import construct_task_config, add_reference_trajectory, load_task_cfg, add_generated_trajectories
from envs.randomizer import Randomizer
from envs.running_cfg import get_rollout_config, get_randomizer_config, get_simulation_config
# ─────────── CLI ───────────
parser = argparse.ArgumentParser("sim_policy")
parser.add_argument("--key", type=str, default="demo_video", help="scene key (outputs/<key>)")
parser.add_argument("--robot", type=str, default="franka")
parser.add_argument("--num_envs", type=int, default=None, help="Number of environments (overrides running_cfg)")
parser.add_argument("--total_num", type=int, default=None, help="Total number of trajectories required (overrides running_cfg)")
AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()
args_cli.enable_cameras = True
args_cli.headless = True # headless mode for batch execution
app_launcher = AppLauncher(vars(args_cli))
simulation_app = app_launcher.app

from sim_utils_demo.transform_utils import pose_to_mat, mat_to_pose, grasp_approach_axis_batch
from sim_utils_demo.sim_utils import load_sim_parameters
# ─────────── Runtime imports ───────────
import isaaclab.sim as sim_utils
from isaaclab.utils.math import subtract_frame_transforms

# ─────────── Simulation environments ───────────
from sim_base_demo import BaseSimulator, get_next_demo_id
from sim_env_factory_demo import make_env


BASE_DIR   = Path.cwd()

out_dir    = BASE_DIR / "outputs"

def pose_distance(T1, T2):
    """
    Compute translation and rotation (angle) distance between two SE(3) transformation matrices in torch.
    Args:
        T1, T2: [..., 4, 4] torch.Tensor or np.ndarray, can be batched
    Returns:
        trans_dist: translation distance(s)
        angle: rotational angle(s)
    """
    if not torch.is_tensor(T1):
        T1 = torch.tensor(T1, dtype=torch.float32)
    if not torch.is_tensor(T2):
        T2 = torch.tensor(T2, dtype=torch.float32)
    
    # Translation distance
    t1 = T1[..., :3, 3]
    t2 = T2[..., :3, 3]
    trans_dist = torch.norm(t2 - t1, dim=-1)

    # Rotation difference (angle)
    R1 = T1[..., :3, :3]
    R2 = T2[..., :3, :3]
    dR = torch.matmul(R2, R1.transpose(-2, -1))
    trace = dR[..., 0, 0] + dR[..., 1, 1] + dR[..., 2, 2]
    cos_angle = (trace - 1) / 2
    
    # Handle numerical precision
    cos_angle = torch.clamp(cos_angle, -1.0, 1.0)
    angle = torch.acos(cos_angle)
    return trans_dist, angle

def compute_poses_from_traj_cfg(traj_cfg_list):
    """
    Extract poses and trajectories from a list of TrajectoryCfg objects.
    
    Args:
        traj_cfg_list: List of TrajectoryCfg objects
        
    Returns:
        robot_poses_list: List of robot poses [7] for each trajectory
        object_poses_dict: Dict mapping oid -> list of (pos, quat) tuples
        object_trajectory_list: List of object trajectories
        final_gripper_state_list: List of final gripper states
        grasping_phase_list: List of grasping phases
        placing_phrase_list: List of placing phases
    """
    robot_poses_list = []
    object_poses_dict = {}  # {oid: [(pos, quat), ...]}
    object_trajectory_list = []
    final_gripper_state_list = []
    pregrasp_pose_list = []
    grasp_pose_list = []
    final_gripper_close_list = []
    end_pose_list = []


    for traj_cfg in traj_cfg_list:
        robot_poses_list.append(traj_cfg.robot_pose)
        
        # Extract object poses: traj_cfg.object_poses is a list of (oid, pose) tuples
        for oid in traj_cfg.object_poses.keys():
            pose = traj_cfg.object_poses[oid]
            oid_str = str(oid)
            if oid_str not in object_poses_dict:
                object_poses_dict[oid_str] = []
            object_poses_dict[oid_str].append(np.array(pose, dtype=np.float32))
        traj = []
        for i in range(len(traj_cfg.object_trajectory)):
            mat = pose_to_mat(traj_cfg.object_trajectory[i][:3], traj_cfg.object_trajectory[i][3:7])
            traj.append(mat)
        object_trajectory_list.append(np.array(traj, dtype=np.float32))
        final_gripper_state_list.append(traj_cfg.final_gripper_close)
        pregrasp_pose_list.append(np.array(traj_cfg.pregrasp_pose, dtype=np.float32))
        grasp_pose_list.append(np.array(traj_cfg.grasp_pose, dtype=np.float32))
        final_gripper_close_list.append(traj_cfg.final_gripper_close)
        end_pose_list.append(np.array(traj_cfg.success_metric.end_pose, dtype=np.float32))
  
    return robot_poses_list, object_poses_dict, object_trajectory_list, final_gripper_state_list, pregrasp_pose_list, grasp_pose_list, end_pose_list



# ────────────────────────────Heuristic Manipulation ────────────────────────────
class RandomizeExecution(BaseSimulator):
    """
    Physical trial-and-error grasping with approach-axis perturbation:
      • Multiple grasp proposals executed in parallel;
      • Every attempt does reset → pre → grasp → close → lift → check;
      • Early stops when any env succeeds; then re-exec for logging.
    """
    def __init__(self, sim, scene, sim_cfgs: dict, data_dir: Path, record: bool = True, args_cli: Optional[argparse.Namespace] = None, bg_rgb: Optional[np.ndarray] = None, goal_offset: float = 0.03, save_interval: int = 1, decimation: int = 1):
        robot_pose = torch.tensor(
            sim_cfgs["robot_cfg"]["robot_pose"],
            dtype=torch.float32,
            device=sim.device,

        )
        super().__init__(
            sim=sim, sim_cfgs=sim_cfgs, scene=scene, args=args_cli,
            robot_pose=robot_pose, cam_dict=sim_cfgs["cam_cfg"],
            out_dir=out_dir, img_folder=args_cli.key, data_dir=data_dir,
            enable_motion_planning=True,
            set_physics_props=True, debug_level=0,
            save_interval=save_interval,
            decimation=decimation,
        )

        self.selected_object_id = sim_cfgs["demo_cfg"]["manip_object_id"]
        self._selected_object_id = str(self.selected_object_id)  # Store as string for mapping
        self._update_object_prim()  # Update object_prim based on selected_object_id
        self.record = record  # Store whether to record data
        #self.traj_cfg_list = traj_cfg_list
       
        self.task_type = sim_cfgs["demo_cfg"]["task_type"]
        self.goal_offset = [0, 0, goal_offset]
        
       
    

    def reset(self, env_ids=None):
        super().reset(env_ids)
        device = self.object_prim.device
        if env_ids is None:
            env_ids_t = self._all_env_ids.to(device)  # (B,)
        else:
            env_ids_t = torch.as_tensor(env_ids, device=device, dtype=torch.long).view(-1)  # (M,)
        M = int(env_ids_t.shape[0])
        # --- object pose/vel: set object at env origins with identity quat ---
        env_origins = self.scene.env_origins.to(device)[env_ids_t]  # (M,3)
        # Set poses for all objects from object_poses_dict
        from sim_env_factory_demo import get_prim_name_from_oid
        for oid in self.object_poses_dict.keys():
            # Get prim name from oid
            prim_name = get_prim_name_from_oid(str(oid))
            object_prim = self.scene[prim_name]
            # Get pose for this object (first pose in the list for now)
            # object_poses_dict[oid] is a list of (pos, quat) tuples from mat_to_pose
            if len(self.object_poses_dict[oid]) == 0:
                continue
            #import ipdb; ipdb.set_trace()
            pos, quat = np.array(self.object_poses_dict[oid], dtype = np.float32)[env_ids_t.cpu().numpy(), :3], np.array(self.object_poses_dict[oid], dtype = np.float32)[env_ids_t.cpu().numpy(), 3:7]
            object_pose = torch.zeros((M, 7), device=device, dtype=torch.float32)
            object_pose[:, :3] = env_origins + torch.tensor(pos, dtype=torch.float32, device=device)
            object_pose[:, 3:7] = torch.tensor(quat, dtype=torch.float32, device=device)  # wxyz
            
            object_prim.write_root_pose_to_sim(object_pose, env_ids=env_ids_t)
            object_prim.write_root_velocity_to_sim(
                torch.zeros((M, 6), device=device, dtype=torch.float32), env_ids=env_ids_t
            )
            object_prim.write_data_to_sim()
        rp_local = np.array(self.robot_poses_list, dtype=np.float32)
        env_origins_robot = self.scene.env_origins.to(device)[env_ids_t]
        robot_pose_world = copy.deepcopy(rp_local)
        #print(f"[RESET DEBUG] rp_local shape: {rp_local.shape}, values:\n{rp_local}")
        #print(f"[RESET DEBUG] env_origins_robot:\n{env_origins_robot.cpu().numpy()}")
        #print(f"[RESET DEBUG] env_ids_t: {env_ids_t.cpu().numpy()}")
        robot_pose_world[:, :3] = env_origins_robot.cpu().numpy() + robot_pose_world[env_ids_t.cpu().numpy(), :3]
        #print(f"[RESET DEBUG] robot_pose_world after assignment:\n{robot_pose_world}")
        #robot_pose_world[:, 3:7] = [1.0, 0.0, 0.0, 0.0]
        self.robot.write_root_pose_to_sim(torch.tensor(robot_pose_world, dtype=torch.float32, device=device), env_ids=env_ids_t)
        self.robot.write_root_velocity_to_sim(
            torch.zeros((M, 6), device=device, dtype=torch.float32), env_ids=env_ids_t
        )
        
        # Set joint positions before updating state buffers
        joint_pos = self.robot.data.default_joint_pos.to(self.robot.device)[env_ids_t]  # (M,7)
        joint_vel = self.robot.data.default_joint_vel.to(self.robot.device)[env_ids_t]  # (M,7)
        self.robot.write_joint_state_to_sim(joint_pos, joint_vel, env_ids=env_ids_t)
        
        # Write all data to simulation at once
        self.robot.write_data_to_sim()

        # Perform a simulation step to update physics with new poses and joints
        self.sim.step(render=False)
        
        # Update robot state buffers to reflect new base poses and joint states
        self.robot.update(dt=self.sim.get_physics_dt())
        
        # Verify EE positions after update
        ee_test = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:3]
        root_test = self.robot.data.root_state_w[:, 0:3]
        #print(f"[RESET VERIFY] After robot.update():")
        #print(f"  Robot base positions: {root_test.cpu().numpy()}")
        #print(f"  EE positions: {ee_test.cpu().numpy()}")
        #print(f"  Expected EE X ~= base X ± 0.5m")

        self.clear_data()

    def compute_components(self):
        self.robot_poses_list, self.object_poses_dict, self.object_trajectory_list, self.final_gripper_state_list, self.pregrasp_pose_list, self.grasp_pose_list, self.end_pose_list = compute_poses_from_traj_cfg(self.traj_cfg_list)
       


    def compute_object_goal_traj(self):
        B = self.scene.num_envs
        # obj_state = self.object_prim.data.root_com_state_w[:, :7]  # [B,7], pos(3)+quat(wxyz)(4)
        obj_state = self.object_prim.data.root_state_w[:, :7]  # [B,7], pos(3)+quat(wxyz)(4)
        #print(f"obj_state shape: {obj_state.shape}")
        self.show_goal(obj_state[:, :3], obj_state[:, 3:7])

        obj_state_np = obj_state.detach().cpu().numpy().astype(np.float32)
        #print(f"obj_state_np shape: {obj_state_np.shape}")
        offset_np = np.asarray(self.goal_offset, dtype=np.float32)
        #print(f"offset_np shape: {offset_np.shape}")
        obj_state_np[:, :3] += offset_np  # raise a bit to avoid collision
        #print(f"obj_state_np after offset addition shape: {obj_state_np.shape}")

        # Note: here the relative traj Δ_w is defined in world frame with origin (0,0,0),
        # Hence, we need to normalize it to each env's origin frame.
        origins = self.scene.env_origins.detach().cpu().numpy().astype(np.float32)  # (B,3)
        #print(origins)
        obj_state_np[:, :3] -= origins # normalize to env origin frame
        #print(f"obj_state_np after origins subtraction shape: {obj_state_np.shape}")

        # —— 3) Precompute absolute object goals for all envs ——
        T = self.object_trajectory_list[0].shape[0]
        #print(f"T: {T}")
        obj_goal = np.zeros((B, T, 4, 4), dtype=np.float32)
        #print(f"obj_goal shape: {obj_goal.shape}")
        for b in range(B):
            for t in range(1, T):
                goal_4x4 = self.object_trajectory_list[b][t].copy()
                goal_4x4[:3, 3] += origins[b]  # back to world frame
                if t < T-1:
                    goal_4x4[:3, 3] += offset_np
                obj_goal[b, t] = goal_4x4
                
        #print("origins:", origins)
        #print("final timestep goal positions (obj positions):", obj_goal[:, -1, :3, 3])
        self.obj_goal_traj_w = obj_goal
        #print(f"self.obj_goal_traj_w shape: {self.obj_goal_traj_w.shape}")


    def lift_up(self, height=0.12, gripper_open=False, steps=8):
        """
        Lift up by a certain height (m) from current EE pose.
        """
        # Force robot state update to ensure FK is current before reading EE pose
        self.robot.update(dt=self.sim.get_physics_dt())
        
        ee_w = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:7]
        root = self.robot.data.root_state_w[:, 0:7]
        
        # Sanity check: EE should be within ~1m of robot base
        ee_to_base_dist = torch.norm(ee_w[:, :3] - root[:, :3], dim=1)
        #print(f"[DEBUG lift_up] EE-to-base distance: {ee_to_base_dist.cpu().numpy()}")
        if torch.any(ee_to_base_dist > 1.5):
            print(f"[ERROR] EE position seems invalid! EE: {ee_w[:, :3].cpu().numpy()}, Root: {root[:, :3].cpu().numpy()}")
            print(f"[ERROR] This suggests stale robot state. Returning current joint pos.")
            return self.robot.data.joint_pos[:, self.robot_entity_cfg.joint_ids]
        
        #print(f"ee_w shape: {ee_w.shape}, positions: {ee_w[:, :3].cpu().numpy()}")
        target_p = ee_w[:, :3].clone()
        #print(f"target_p shape: {target_p.shape}, values: {target_p.cpu().numpy()}")
        target_p[:, 2] += height
        #print(f"target_p after height addition: {target_p.cpu().numpy()}")

        #print(f"root shape: {root.shape}")
        #print(f"robot root_state_w positions: {root[:, 0:3].cpu().numpy()}")
        p_lift_b, q_lift_b = subtract_frame_transforms(
            root[:, 0:3], root[:, 3:7],
            target_p, ee_w[:, 3:7]
        ) # [B,3], [B,4]
        #print(f"p_lift_b shape: {p_lift_b.shape}, values: {p_lift_b.cpu().numpy()}")
        #print(f"q_lift_b shape: {q_lift_b.shape}, values: {q_lift_b.cpu().numpy()}")
        jp, success = self.move_to(p_lift_b, q_lift_b, gripper_open=gripper_open)
        
        if jp is None:
            print("[ERROR] lift_up: move_to returned None! Returning current joint pos.")
            return self.robot.data.joint_pos[:, self.robot_entity_cfg.joint_ids]

        jp = self.wait(gripper_open=gripper_open, steps=steps)
        return jp

    def follow_object_goals(self, start_joint_pos, sample_step=1, recalibrate_interval = 3, visualize=True):
        """
        follow precompute object absolute trajectory: self.obj_goal_traj_w:
          T_obj_goal[t] = Δ_w[t] @ T_obj_init

        EE-object transform is fixed:
          T_ee_goal[t] = T_obj_goal[t] @ (T_obj_grasp^{-1} @ T_ee_grasp)
        Here T_obj_grasp / T_ee_grasp is the transform at the moment of grasping.
        """
        B = self.scene.num_envs
        obj_goal_all = self.obj_goal_traj_w  # [B, T, 4, 4]
        T = obj_goal_all.shape[1]

       
        joint_pos = start_joint_pos
        
        # Force robot state update before reading poses
        self.robot.update(dt=self.sim.get_physics_dt())
        
        root_w = self.robot.data.root_state_w[:, 0:7]  # robot base poses per env

        t_iter = list(range(1, T, sample_step))
        t_iter = t_iter + [T-1] if t_iter[-1] != T-1 else t_iter


        ee_pos_initial = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:3]
        obj_pos_initial = self.object_prim.data.root_com_pos_w[:, 0:3]
        initial_grasp_dist = torch.norm(ee_pos_initial - obj_pos_initial, dim=1) # [B]
        self.initial_grasp_dist = initial_grasp_dist
        
        # Debug: verify EE position is valid
        ee_to_base_dist = torch.norm(ee_pos_initial - root_w[:, :3], dim=1)
        #print(f"[DEBUG follow_object_goals] Initial EE-to-base distance: {ee_to_base_dist.cpu().numpy()}")
        
        T_ee_in_obj = None
        for t in t_iter:
            if recalibrate_interval> 0 and (t-1) % recalibrate_interval == 0:
                # Force robot state update before recalibration
                self.robot.update(dt=self.sim.get_physics_dt())
                
                ee_w  = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:7]  # [B,7]
                obj_w = self.object_prim.data.root_state_w[:, :7]                                 # [B,7]
                T_ee_in_obj = []
                for b in range(B):
                    T_ee_w  = pose_to_mat(ee_w[b, :3],  ee_w[b, 3:7])
                    T_obj_w = pose_to_mat(obj_w[b, :3], obj_w[b, 3:7])
                    T_ee_in_obj.append((np.linalg.inv(T_obj_w) @ T_ee_w).astype(np.float32))
                self.T_ee_in_obj = T_ee_in_obj
            goal_pos_list, goal_quat_list = [], []
            print(f"[INFO] follow object goal step {t}/{T}")
            for b in range(B):
                T_obj_goal = obj_goal_all[b, t]            # (4,4)
                T_ee_goal  = T_obj_goal @ T_ee_in_obj[b]   # (4,4)
                pos_b, quat_b = mat_to_pose(T_ee_goal)
                goal_pos_list.append(pos_b.astype(np.float32))
                goal_quat_list.append(quat_b.astype(np.float32))

            goal_pos  = torch.as_tensor(np.stack(goal_pos_list),  dtype=torch.float32, device=self.sim.device)
            goal_quat = torch.as_tensor(np.stack(goal_quat_list), dtype=torch.float32, device=self.sim.device)

            if visualize:
                self.show_goal(goal_pos, goal_quat)
            ee_pos_b, ee_quat_b = subtract_frame_transforms(
                root_w[:, :3], root_w[:, 3:7], goal_pos, goal_quat
            )
            res = self.move_to(ee_pos_b, ee_quat_b, gripper_open=False)
            if res is None:
                 print(f"[ERROR] follow_object_goals: move_to returned None at step {t}!")
                 continue
            joint_pos, success = res


            self.save_dict["actions"].append(np.concatenate([ee_pos_b.cpu().numpy(), ee_quat_b.cpu().numpy(), np.ones((B, 1))], axis=1))
            action_index = np.ones((B, 1)) * self.get_current_frame_count()
            self.save_dict["action_indices"].append(action_index)
                
        is_grasp_success = self.is_grasp_success()
        is_success = self.is_success()

        print('[INFO] last obj goal', obj_goal_all[:, -1])
        print('[INFO] last obj pos', self.object_prim.data.root_state_w[:, :3])
        for b in range(B):
            if self.final_gripper_state_list[b]:
                self.wait(gripper_open=False, steps=10, record = self.record)
            else:
                self.wait(gripper_open=True, steps=10, record = self.record)

        return joint_pos, is_success


    def follow_object_centers(self, start_joint_pos, sample_step=1, recalibrate_interval = 3, visualize=True):
        B = self.scene.num_envs
        obj_goal_all = self.obj_goal_traj_w  # [B, T, 4, 4]
        T = obj_goal_all.shape[1]

        joint_pos = start_joint_pos
        
        # Force robot state update before reading poses
        self.robot.update(dt=self.sim.get_physics_dt())
        
        root_w = self.robot.data.root_state_w[:, 0:7]  # robot base poses per env

        t_iter = list(range(1, T, sample_step))
        t_iter = t_iter + [T-1] if t_iter[-1] != T-1 else t_iter

        ee_pos_initial = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:3]
        obj_pos_initial = self.object_prim.data.root_com_pos_w[:, 0:3]
        initial_grasp_dist = torch.norm(ee_pos_initial - obj_pos_initial, dim=1) # [B]
        self.initial_grasp_dist = initial_grasp_dist


        for t in t_iter:
            if recalibrate_interval> 0 and (t-1) % recalibrate_interval == 0:
                # Force robot state update before recalibration
                self.robot.update(dt=self.sim.get_physics_dt())
                
                ee_w  = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:7]  # [B,7]
                # obj_w = self.object_prim.data.root_com_state_w[:, :7]                                 # [B,7]
                obj_w = self.object_prim.data.root_state_w[:, :7]                                 # [B,7]
                T_ee_ws = []
                T_obj_ws = []
                for b in range(B):
                    T_ee_w  = pose_to_mat(ee_w[b, :3],  ee_w[b, 3:7])
                    T_obj_w = pose_to_mat(obj_w[b, :3], obj_w[b, 3:7])
                    T_ee_ws.append(T_ee_w)
                    T_obj_ws.append(T_obj_w)
                print(f"[INFO] recalibrated at step {t}/{T}")

            goal_pos_list, goal_quat_list = [], []
            print(f"[INFO] follow object goal step {t}/{T}")
            for b in range(B):
                T_obj_goal = obj_goal_all[b, t]          
                trans_offset = T_obj_goal - T_obj_ws[b]
                T_ee_goal  = T_ee_ws[b] + trans_offset
                pos_b, quat_b = mat_to_pose(T_ee_goal)

                goal_pos_list.append(pos_b.astype(np.float32))
                goal_quat_list.append(quat_b.astype(np.float32))

            goal_pos  = torch.as_tensor(np.stack(goal_pos_list),  dtype=torch.float32, device=self.sim.device)
            goal_quat = ee_w[:, 3:7]

            if visualize:
                self.show_goal(goal_pos, goal_quat)
            ee_pos_b, ee_quat_b = subtract_frame_transforms(
                root_w[:, :3], root_w[:, 3:7], goal_pos, goal_quat
            )
            res = self.move_to(ee_pos_b, ee_quat_b, gripper_open=False, record = self.record)
            if res is None:
                 print(f"[ERROR] follow_object_centers: move_to returned None at step {t}!")
                 continue
            joint_pos, success = res

            print(obj_goal_all[:,t])
            print(self.object_prim.data.root_state_w[:, :7])
            self.save_dict["actions"].append(np.concatenate([ee_pos_b.cpu().numpy(), ee_quat_b.cpu().numpy(), np.ones((B, 1))], axis=1))
            action_index = np.ones((B, 1)) * self.get_current_frame_count()
            self.save_dict["action_indices"].append(action_index)
        is_grasp_success = self.is_grasp_success()
        # print('[INFO] last obj goal', obj_goal_all[:, -1])
        # print('[INFO] last obj pos', self.object_prim.data.root_state_w[:, :3])
        for b in range(B):
            if self.final_gripper_state_list[b]:
                self.wait(gripper_open=False, steps=10, record = self.record)
            else:
                self.wait(gripper_open=True, steps=10, record = self.record)

        return joint_pos, is_grasp_success


    def refine_grasp_pose(self, init_root_pose, grasp_pose, pregrasp_pose):
        """
        Refine grasp and pregrasp poses based on the difference between 
        reference root pose (from traj) and current root pose.
        
        Args:
            init_root_pose: (B, 7) reference root pose [pos(3) + quat(4)] from traj
            grasp_pose: (B, 3) grasp positions in world frame
            pregrasp_pose: (B, 3) pregrasp positions in world frame
        
        Returns:
            grasp_pose_w: (B, 3) refined grasp positions
            pregrasp_pose_w: (B, 3) refined pregrasp positions
        """
        # Get current root pose from API (in world frame)
        current_root_pose_w = self.object_prim.data.root_state_w[:, :7].cpu().numpy()  # (B, 7)
        env_origins = self.scene.env_origins.cpu().numpy()  # (B, 3)
        
        # Convert to numpy if needed
        if isinstance(init_root_pose, torch.Tensor):
            init_root_pose = init_root_pose.cpu().numpy()
        if isinstance(grasp_pose, torch.Tensor):
            grasp_pose = grasp_pose.cpu().numpy()
        if isinstance(pregrasp_pose, torch.Tensor):
            pregrasp_pose = pregrasp_pose.cpu().numpy()
        
        # Ensure init_root_pose has batch dimension
        if init_root_pose.ndim == 1:
            init_root_pose = init_root_pose[np.newaxis, :].repeat(grasp_pose.shape[0], axis=0)
        
        # Convert current root pose to local frame (relative to env_origin)
        current_root_pose = current_root_pose_w.copy()
        current_root_pose[:, :3] -= env_origins  # Convert to local frame
        
        # Calculate pose difference (both in local frame)
        ref_pos = init_root_pose[:, :3]  # (B, 3) - reference pose in local frame
        ref_quat = init_root_pose[:, 3:7]  # (B, 4)
        curr_pos = current_root_pose[:, :3]  # (B, 3) - current pose in local frame
        curr_quat = current_root_pose[:, 3:7]  # (B, 4)
        
        # Make copies to avoid modifying input arrays
        grasp_pose_w = grasp_pose.copy()  # (B, 3)
        pregrasp_pose_w = pregrasp_pose.copy()  # (B, 3)
        
        B = grasp_pose.shape[0]
        for b in range(B):
            # Calculate position offset
            pos_offset = curr_pos[b] - ref_pos[b]  # (3,)
            
            # Calculate rotation difference: delta_quat = curr_quat * ref_quat^-1
            ref_mat = transforms3d.quaternions.quat2mat(ref_quat[b])
            curr_mat = transforms3d.quaternions.quat2mat(curr_quat[b])
            delta_mat = curr_mat @ ref_mat.T  # rotation from ref to curr
            
            # Transform grasp and pregrasp positions
            # Note: grasp_pose and pregrasp_pose are in world frame
            # We need to convert them to local frame first, then transform, then back to world frame
            
            # Convert to local frame (relative to env_origin)
            grasp_pos_local = grasp_pose_w[b] - env_origins[b]  # (3,)
            pregrasp_pos_local = pregrasp_pose_w[b] - env_origins[b]  # (3,)
            
            # Express positions relative to reference frame
            grasp_pos_rel = grasp_pos_local - ref_pos[b]  # (3,)
            pregrasp_pos_rel = pregrasp_pos_local - ref_pos[b]  # (3,)
            
            # Apply rotation
            grasp_pos_rotated = delta_mat @ grasp_pos_rel  # (3,)
            pregrasp_pos_rotated = delta_mat @ pregrasp_pos_rel  # (3,)
            
            # Translate to current frame (in local frame)
            grasp_pos_new_local = curr_pos[b] + grasp_pos_rotated
            pregrasp_pos_new_local = curr_pos[b] + pregrasp_pos_rotated
            
            # Convert back to world frame
            grasp_pose_w[b] = grasp_pos_new_local + env_origins[b]
            pregrasp_pose_w[b] = pregrasp_pos_new_local + env_origins[b]
        
        return grasp_pose_w, pregrasp_pose_w

    # def is_success(self):
    #     obj_w = self.object_prim.data.root_state_w[:, :7]
    #     origins = self.scene.env_origins
    #     obj_w[:, :3] -= origins
    #     trans_dist_list = []
    #     angle_list = []
    #     B = self.scene.num_envs
    #     for b in range(B):
    #         obj_pose_l = pose_to_mat(obj_w[b, :3], obj_w[b, 3:7])
    #         goal_pose_l = pose_to_mat(self.end_pose_list[b][:3], self.end_pose_list[b][3:7])
    #         trans_dist, angle = pose_distance(obj_pose_l, goal_pose_l)
    #         trans_dist_list.append(trans_dist)
    #         angle_list.append(angle)
    #     trans_dist = torch.tensor(np.stack(trans_dist_list))
    #     angle = torch.tensor(np.stack(angle_list))
    #     print(f"[INFO] trans_dist: {trans_dist}, angle: {angle}")
    #     if self.task_type == "simple_pick_place" or self.task_type == "simple_pick":
    #         is_success = trans_dist < 0.10
    #     elif self.task_type == "targetted_pick_place":
    #         is_success = (trans_dist < 0.10) & (angle < np.radians(10))
    #     else:
    #         raise ValueError(f"[ERR] Invalid task type: {self.task_type}")
    #     return is_success.cpu().numpy()

    
    def is_success(self, position_threshold: float = 0.10, gripper_threshold: float = 0.10, holding_threshold: float = 0.02) -> torch.Tensor:
        """
        Verify if the manipulation task succeeded by checking:
        1. Object is at Goal (Distance < 10cm)
        2. Gripper is at Goal (Distance < 10cm) - Explicit check using T_ee_in_obj
        3. Object is in Gripper (Deviation < 2cm)
        
        Args:
            position_threshold: Distance threshold for Object-Goal check (default: 0.10m = 10cm)
            skip_envs: Boolean array [B] indicating which envs to skip from verification
        
        Returns:
            torch.Tensor: Boolean tensor [B] indicating success for each environment
        """
        B = self.scene.num_envs
        # --- 1. Object Goal Check ---
        final_goal_matrices = self.obj_goal_traj_w[:, -1, :, :]  # [B, 4, 4]
        goal_positions_np = final_goal_matrices[:, :3, 3]
        goal_positions = torch.tensor(goal_positions_np, dtype=torch.float32, device=self.sim.device)
        
        # Current Root and COM
        current_root_state = self.object_prim.data.root_state_w
        current_root_pos = current_root_state[:, :3]
        current_root_quat = current_root_state[:, 3:7]
        current_com_pos = self.object_prim.data.root_com_pos_w[:, :3]
        
        # Calculate Goal COM positions
        # The COM offset is constant in the object's local frame.
        # We need to: (1) Get the current COM offset in local frame, (2) Apply to goal pose
        goal_com_positions_list = []
        for b in range(B):
            # Current state
            root_pos_cur = current_root_pos[b].cpu().numpy()
            root_quat_cur = current_root_quat[b].cpu().numpy()  # wxyz format
            com_pos_cur = current_com_pos[b].cpu().numpy()
            
            # COM offset in world frame
            com_offset_world = com_pos_cur - root_pos_cur  # [3]
            
            # Convert COM offset to object's local frame
            # R_cur^T @ com_offset_world gives the offset in local coords (assuming no scale)
            R_cur = transforms3d.quaternions.quat2mat(root_quat_cur)  # Convert wxyz to rotation matrix
            com_offset_local = R_cur.T @ com_offset_world  # Rotate to local frame
            
            # Goal state
            T_goal_root = final_goal_matrices[b]  # [4, 4] numpy array
            goal_root_pos = T_goal_root[:3, 3]
            R_goal = T_goal_root[:3, :3]
            
            # Apply local offset to goal pose
            # goal_com_pos = goal_root_pos + R_goal @ com_offset_local
            com_offset_world_goal = R_goal @ com_offset_local
            goal_com_pos = goal_root_pos + com_offset_world_goal
            
            goal_com_positions_list.append(goal_com_pos)
            
        goal_com_positions = torch.tensor(np.array(goal_com_positions_list), dtype=torch.float32, device=self.sim.device)
        
        # Calculate Distances
        root_dist = torch.norm(current_root_pos - goal_positions, dim=1)
        com_dist = torch.norm(current_com_pos - goal_com_positions, dim=1)
        
        # Success requires BOTH Root and COM to be within threshold
        obj_success = (root_dist <= position_threshold) & (com_dist <= position_threshold)

        # --- 2. Gripper Goal Check ---
        # Calculate Target Gripper Pose: T_ee_goal = T_obj_goal @ T_ee_in_obj
        # We use the stored T_ee_in_obj from the start of the trajectory
        ee_pos_final = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:3]
        
        if hasattr(self, 'T_ee_in_obj') and self.T_ee_in_obj is not None:
            target_ee_pos_list = []
            for b in range(B):
                T_obj_goal = final_goal_matrices[b]
                T_ee_goal = T_obj_goal @ self.T_ee_in_obj[b]
                target_ee_pos_list.append(T_ee_goal[:3, 3])
            
            target_ee_pos = torch.tensor(np.array(target_ee_pos_list), dtype=torch.float32, device=self.sim.device)
            grip_goal_dist = torch.norm(ee_pos_final - target_ee_pos, dim=1)
            gripper_success = grip_goal_dist <= 0.10
        else:
            # Fallback if T_ee_in_obj not available (should not happen if follow_object_goals ran)
            print("[WARN] T_ee_in_obj not found, skipping explicit Gripper Goal Check")
            gripper_success = torch.ones(B, dtype=torch.bool, device=self.sim.device)
            grip_goal_dist = torch.zeros(B, dtype=torch.float32, device=self.sim.device)

        # --- 3. Holding Check (Object in Gripper) ---
        # Check if the distance between Gripper and Object COM has remained stable.
        # We compare the final distance to the initial grasp distance.
        obj_com_final = self.object_prim.data.root_com_pos_w[:, 0:3]
        current_grip_com_dist = torch.norm(ee_pos_final - obj_com_final, dim=1)
        
        if hasattr(self, 'initial_grasp_dist') and self.initial_grasp_dist is not None:
            grasp_deviation = torch.abs(current_grip_com_dist - self.initial_grasp_dist)
            holding_success = grasp_deviation <= 0.02
            
            holding_metric = grasp_deviation
            holding_threshold = 0.02
            holding_metric_name = "Grip-COM Deviation"
        else:
            holding_success = current_grip_com_dist <= 0.15
            holding_metric = current_grip_com_dist
            holding_threshold = 0.15
            holding_metric_name = "Grip-COM Dist"

        # Combined Success
        success_mask = obj_success & gripper_success & holding_success
       
        print("="*50)
        print(f"TASK VERIFIER: SUCCESS - {success_mask.sum().item()}/{B} environments succeeded")
        print("="*50 + "\n")
        
        return success_mask


    def is_grasp_success(self):
        ee_w  = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:7]
        obj_w = self.object_prim.data.root_com_pos_w[:, 0:3]
        dist = torch.norm(obj_w[:, :3] - ee_w[:, :3], dim=1) # [B]
        # print(f"[INFO] dist: {dist}")
        return (dist < 0.15).cpu().numpy()


    def viz_object_goals(self, sample_step=1, hold_steps=20):
        self.reset()
        self.wait(gripper_open=True, steps=10, record = False)
        B = self.scene.num_envs
        env_ids = torch.arange(B, device=self.object_prim.device, dtype=torch.long)
        goals = self.obj_goal_traj_w
        t_iter = list(range(0, goals.shape[1], sample_step))
        t_iter = t_iter + [goals.shape[1]-1] if t_iter[-1] != goals.shape[1]-1 else t_iter
        t_iter = t_iter[-1:]
        for t in t_iter:
            print(f"[INFO] viz object goal step {t}/{goals.shape[1]}")
            pos_list, quat_list = [], []
            for b in range(B):
                pos, quat = mat_to_pose(goals[b, t])
                pos_list.append(pos.astype(np.float32))
                quat_list.append(quat.astype(np.float32))
            pose = self.object_prim.data.root_state_w[:, :7]
            # pose = self.object_prim.data.root_com_state_w[:, :7]
            pose[:, :3]   = torch.tensor(np.stack(pos_list),  dtype=torch.float32, device=pose.device)
            pose[:, 3:7]  = torch.tensor(np.stack(quat_list), dtype=torch.float32, device=pose.device)
            self.show_goal(pose[:, :3], pose[:, 3:7])

            for _ in range(hold_steps):
                self.object_prim.write_root_pose_to_sim(pose, env_ids=env_ids)
                self.object_prim.write_data_to_sim()
                self.step()

    # ---------- Helpers ----------
    def _to_base(self, pos_w: np.ndarray | torch.Tensor, quat_w: np.ndarray | torch.Tensor):
        """World → robot base frame for all envs."""
        root = self.robot.data.root_state_w[:, 0:7]  # [B,7]
        p_w, q_w = self._ensure_batch_pose(pos_w, quat_w)
        pb, qb = subtract_frame_transforms(
            root[:, 0:3], root[:, 3:7], p_w, q_w
        )
        return pb, qb  # [B,3], [B,4]

    # ---------- Batched execution & lift-check ----------
    def build_grasp_info(
        self,
        grasp_pos_w_batch: np.ndarray,   # (B,3)  GraspNet proposal in world frame
        grasp_quat_w_batch: np.ndarray,  # (B,4)  wxyz
        pregrasp_pos_w_batch: np.ndarray,
        pregrasp_quat_w_batch: np.ndarray,

    ) -> dict:
        B = self.scene.num_envs
        p_w   = np.asarray(grasp_pos_w_batch,  dtype=np.float32).reshape(B, 3)
        q_w   = np.asarray(grasp_quat_w_batch, dtype=np.float32).reshape(B, 4)
        pre_p_w = np.asarray(pregrasp_pos_w_batch, dtype=np.float32).reshape(B, 3)
        pre_q_w = np.asarray(pregrasp_quat_w_batch, dtype=np.float32).reshape(B, 4)
    
        # Inputs are already in World Frame, no need to add origins
        # origins = self.scene.env_origins.detach().cpu().numpy().astype(np.float32)  # (B,3)
        # pre_p_w = pre_p_w + origins
        # p_w = p_w + origins

        pre_pb, pre_qb = self._to_base(pre_p_w, pre_q_w)
        pb, qb = self._to_base(p_w, q_w)

        return {
            "pre_p_w": pre_p_w, "p_w": p_w, "q_w": q_w,
            "pre_p_b": pre_pb,  "pre_q_b": pre_qb,
            "p_b": pb,      "q_b": qb,
        }
    

    def inference(self) -> list[int]:
        """
        Main function of the heuristic manipulation policy.
        Physical trial-and-error grasping with approach-axis perturbation:
          • Multiple grasp proposals executed in parallel;
          • Every attempt does reset → pre → grasp → close → lift → check;
          • Early stops when any env succeeds; then re-exec for logging.
        """
        B = self.scene.num_envs

        #self.wait(gripper_open=True, steps=10, record = self.record)
        # reset and conduct main process: open→pre→grasp→close→follow_object_goals
        self.reset()

        cam_p = self.camera.data.pos_w
        cam_q = self.camera.data.quat_w_ros
        
        # Treat grasp_pose_list as Local Frame (relative to env origin) and convert to World Frame
        gp_local = torch.as_tensor(np.array(self.grasp_pose_list,  dtype=np.float32)[:,:3], dtype=torch.float32, device=self.sim.device)
        gp_w = gp_local + self.scene.env_origins
        
        gq_w  = torch.as_tensor(np.array(self.grasp_pose_list, dtype=np.float32)[:,3:7], dtype=torch.float32, device=self.sim.device)
        
        pre_local = torch.as_tensor(np.array(self.pregrasp_pose_list, dtype=np.float32)[:,:3], dtype=torch.float32, device=self.sim.device)
        pre_w = pre_local + self.scene.env_origins
        
        # Get reference root pose from reset state (after reset, object is at env_origin with identity quat)
        # This is the reference pose from the traj
        init_root_pose = self.object_prim.data.root_state_w[:, :7].cpu().numpy()  # (B, 7)
        init_root_pose[:, :3] -= self.scene.env_origins.cpu().numpy()  # Convert to local frame
        
        # Refine grasp and pregrasp poses based on current vs reference root pose
        gp_w, pre_w = self.refine_grasp_pose(init_root_pose, gp_w, pre_w)
        gp_w = torch.as_tensor(gp_w, dtype=torch.float32, device=self.sim.device)
        pre_w = torch.as_tensor(pre_w, dtype=torch.float32, device=self.sim.device)
        gp_cam,  gq_cam  = subtract_frame_transforms(cam_p, cam_q, gp_w,  gq_w)
        pre_cam, pre_qcm = subtract_frame_transforms(cam_p, cam_q, pre_w, gq_w)
        self.save_dict["grasp_pose_cam"]    = torch.cat([gp_cam,  gq_cam],  dim=1).unsqueeze(0).cpu().numpy()
        self.save_dict["pregrasp_pose_cam"] = torch.cat([pre_cam, pre_qcm], dim=1).unsqueeze(0).cpu().numpy()

        jp = self.robot.data.joint_pos[:, self.robot_entity_cfg.joint_ids]
        self.wait(gripper_open=True, steps=4, record = self.record)

        # pre → grasp
        info_all = self.build_grasp_info(gp_w.cpu().numpy(), gq_w.cpu().numpy(), pre_w.cpu().numpy(), gq_w.cpu().numpy())
        print("[INFO] move_to(pregrasp)")
        import time
        time_start = time.time()
        res = self.move_to(info_all["pre_p_b"], info_all["pre_q_b"], gripper_open=True, record = self.record)
        time_end = time.time()
        print(f"[INFO] move_to(pregrasp) time: {time_end - time_start} seconds")
        if res is None:
             print("[ERROR] inference: move_to (pregrasp) returned None!")
             return []
        jp, success = res
        if torch.all(success==False): return []
        self.save_dict["actions"].append(np.concatenate([info_all["pre_p_b"].cpu().numpy(), info_all["pre_q_b"].cpu().numpy(), np.zeros((B, 1))], axis=1))
        action_index = np.ones((B, 1)) * self.get_current_frame_count()
        self.save_dict["action_indices"].append(action_index)

        jp = self.wait(gripper_open=True, steps=3, record = self.record)
        print("[INFO] move_to(grasp)")
        res = self.move_to(info_all["p_b"], info_all["q_b"], gripper_open=True, record = self.record)
        if res is None:
            print("[ERROR] inference: move_to (grasp) returned None!")
            return []
        jp, success = res
        if torch.all(success==False): return []
        self.save_dict["actions"].append(np.concatenate([info_all["p_b"].cpu().numpy(), info_all["q_b"].cpu().numpy(), np.zeros((B, 1))], axis=1))
        action_index = np.ones((B, 1)) * self.get_current_frame_count()
        self.save_dict["action_indices"].append(action_index)

        # close gripper
        jp = self.wait(gripper_open=False, steps=50, record = self.record)
        self.save_dict["actions"].append(np.concatenate([info_all["p_b"].cpu().numpy(), info_all["q_b"].cpu().numpy(), np.ones((B, 1))], axis=1))
        action_index = np.ones((B, 1)) * self.get_current_frame_count()
        self.save_dict["action_indices"].append(action_index)

        # Debug: Check robot state before lift_up
        self.robot.update(dt=self.sim.get_physics_dt())
        ee_check = self.robot.data.body_state_w[:, self.robot_entity_cfg.body_ids[0], 0:3]
        root_check = self.robot.data.root_state_w[:, 0:3]
        #print(f"[DEBUG Before lift_up] EE positions: {ee_check.cpu().numpy()}")
        #print(f"[DEBUG Before lift_up] Robot bases: {root_check.cpu().numpy()}")
        #print(f"[DEBUG Before lift_up] EE-base diff: {(ee_check - root_check).cpu().numpy()}")

        # object goal following
        self.lift_up(height=self.goal_offset[2], gripper_open=False, steps=8)
        # if self.task_type == "simple_pick_place" or self.task_type == "simple_pick":
        #     jp, is_success = self.follow_object_centers(jp, sample_step=1, visualize=True)
        # elif self.task_type == "targetted_pick_place":
        #     jp, is_success = self.follow_object_goals(jp, sample_step=1, visualize=True)
        # else:
        #     raise ValueError(f"[ERR] Invalid task type: {self.task_type}")
        #jp = self.follow_object_goals(jp, sample_step=1, visualize=True)
        jp, is_success = self.follow_object_goals(jp, sample_step=1, visualize=True)

        is_success = is_success #& self.is_success()
        # Arrange the output: we want to collect only the successful env ids as a list.
        is_success = torch.tensor(is_success, dtype=torch.bool, device=self.sim.device)
        success_env_ids = torch.where(is_success)[0].cpu().numpy().tolist()

        print(f"[INFO] success_env_ids: {success_env_ids}")
        if self.record:
            import time
            t_save_start = time.time()
            self.save_data(ignore_keys=["segmask", "depth"], env_ids=success_env_ids, export_hdf5=True)
            print(f"[TIMING] save_data took {time.time() - t_save_start:.2f}s")
        
        return success_env_ids

    def run_batch_trajectory(self, traj_cfg_list: List[TrajectoryCfg]):
        import time
        t_start = time.time()
        
        self.traj_cfg_list = traj_cfg_list
        self.compute_components()
        self.compute_object_goal_traj()
        
        t_inference_start = time.time()
        result = self.inference()
        print(f"[TIMING] inference took {time.time() - t_inference_start:.2f}s")
        print(f"[TIMING] run_batch_trajectory total: {time.time() - t_start:.2f}s")
        
        return result
    




# ──────────────────────────── Entry Point ────────────────────────────

  
def extract_randomizer_config(randomizer_cfg: RandomizerCfg):
    randomzier_config = {}
    randomzier_config["grid_dist"] = randomizer_cfg.grid_dist
    randomzier_config["grid_num"] = randomizer_cfg.grid_num
    randomzier_config["angle_random_range"] = randomizer_cfg.angle_random_range
    randomzier_config["angle_random_num"] = randomizer_cfg.angle_random_num
    randomzier_config["traj_randomize_num"] = randomizer_cfg.traj_randomize_num
    randomzier_config["scene_randomize_num"] = randomizer_cfg.scene_randomize_num
    randomzier_config["robot_pose_randomize_range"] = randomizer_cfg.robot_pose_randomize_range
    randomzier_config["robot_pose_randomize_angle"] = randomizer_cfg.robot_pose_randomize_angle
    randomzier_config["robot_pose_randomize_num"] = randomizer_cfg.robot_pose_randomize_num
    randomzier_config["fix_end_pose"] = randomizer_cfg.fix_end_pose
    BASE_DIR = Path.cwd()
    task_folder = BASE_DIR / "tasks" / key
    task_folder.mkdir(parents=True, exist_ok=True)
    task_file = task_folder / "randomizer_cfg.json"
    with open(task_file, "w") as f:
        json.dump(randomzier_config, f)
    return randomzier_config


def sim_randomize_rollout(keys: list[str], args_cli: argparse.Namespace):
    for key in keys:
        # Load config from running_cfg, allow CLI args to override
        rollout_cfg = get_rollout_config(key)
        randomizer_cfg = get_randomizer_config(key)
        simulation_cfg = get_simulation_config(key)
        total_require_traj_num = rollout_cfg.total_num
        num_envs = rollout_cfg.num_envs
        goal_offset = rollout_cfg.goal_offset
        save_interval = simulation_cfg.save_interval
        physics_freq = simulation_cfg.physics_freq
        decimation = simulation_cfg.decimation
        print(f"[INFO] Using config for key '{key}': num_envs={num_envs}, total_num={total_require_traj_num}")
        print(f"[INFO] Randomizer config: {randomizer_cfg.to_kwargs()}")
        
        success_trajectory_config_list = []
        task_json_path = BASE_DIR / "tasks" / key / "task.json"
        task_cfg = load_task_cfg(task_json_path)
        randomizer = Randomizer(task_cfg)
        
        # Use randomizer config from running_cfg
        randomizer_kwargs = randomizer_cfg.to_kwargs()
        random_task_cfg_list = randomizer.generate_randomized_scene_cfg(**randomizer_kwargs)

        args_cli.key = key
        sim_cfgs = load_sim_parameters(BASE_DIR, key)
      
        data_dir = BASE_DIR / "h5py" / key
        current_timestep = 0
        env, _ = make_env(
                cfgs=sim_cfgs, num_envs=num_envs,
                device=args_cli.device,
                bg_simplify=False,
                physics_freq=physics_freq,
            )
        sim, scene = env.sim, env.scene

        my_sim = RandomizeExecution(sim, scene, sim_cfgs=sim_cfgs, data_dir=data_dir, record=True, args_cli=args_cli, goal_offset=goal_offset, save_interval=save_interval, decimation=decimation)
        my_sim.task_cfg = task_cfg
        
        import time
        while len(success_trajectory_config_list) < total_require_traj_num:
            iteration_start = time.time()
            
            traj_cfg_list = random_task_cfg_list[current_timestep: current_timestep + num_envs]
            current_timestep += num_envs
           
            success_env_ids = my_sim.run_batch_trajectory(traj_cfg_list)
            
            # Don't close env in the loop - keep it alive for next iteration!
            if len(success_env_ids) > 0:
                for env_id in success_env_ids:
                    success_trajectory_config_list.append(traj_cfg_list[env_id])
                    add_generated_trajectories(task_cfg, [traj_cfg_list[env_id]], task_json_path.parent)
            
            print(f"[INFO] success_trajectory_config_list: {len(success_trajectory_config_list)}/{total_require_traj_num}")
            print(f"[TIMING] Full iteration took {time.time() - iteration_start:.2f}s\n")
        
        # Close env only once at the end
        print("[INFO] Closing environment...")
        env.close()

        # for timestep in range(len(success_trajectory_config_list),10):
        #     traj_cfg_list = random_task_cfg_list[timestep: min(timestep + 10, len(random_task_cfg_list))]
        #     my_sim = RandomizeExecution(sim, scene, sim_cfgs=sim_cfgs, traj_cfg_list=traj_cfg_list, record=True)
        #     success_env_ids = my_sim.inference()
        #     del my_sim
        #     torch.cuda.empty_cache()
       
    
    return success_trajectory_config_list

def main():
    base_dir = Path.cwd()
    cfg = yaml.safe_load((base_dir / "config" / "config.yaml").open("r"))
    keys = cfg["keys"]
    sim_randomize_rollout(keys, args_cli)
  

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        import traceback
        traceback.print_exc()
        sys.exit(1)
    finally:
        simulation_app.close()